{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37cdf478-15a3-43fa-baf9-e310e9ee974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define input and output directories\n",
    "# input_folder = \"raw_data\"\n",
    "# output_folder = \"cleaned_data\"\n",
    "\n",
    "# # Create output folder if it doesn't exist\n",
    "# os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af2180f-ed9d-47e4-8fca-427b0285a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_file(file_path):\n",
    "\n",
    "    # converts filepath extension to lowercase\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    # Handle .csv files\n",
    "    \"\"\"pd.read_csv expects a file path as its argument - above line of code will not work\n",
    "    because it is being passed a DataFrame/ Series object created by load file method and saved\n",
    "    to variable named 'file'\n",
    "    \"\"\"\n",
    "    if ext == '.csv':\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "    # Handle excel spreadsheet files\n",
    "    elif ext in ['.xls', '.xlsx']:\n",
    "        return pd.read_excel(file_path)\n",
    "    \n",
    "    # All other files\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "    df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\data_scientist\\csv_files\\messy_crm_dataset.csv')\n",
    "    print(df.info())\n",
    "\n",
    "# file_toBe_cleansed = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\data_scientist\\csv_files\\messy_crm_dataset.csv')\n",
    "# # return file_toBe_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7860d2-f096-4e88-bd39-6519ba429048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   customer_id        500 non-null    object\n",
      " 1   name               500 non-null    object\n",
      " 2   email              475 non-null    object\n",
      " 3   phone_number       482 non-null    object\n",
      " 4   city               500 non-null    object\n",
      " 5   registration_date  487 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 23.6+ KB\n",
      "(500, 6) \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Call load_file function \n",
    "file_toBe_cleansed = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\data_scientist\\csv_files\\messy_crm_dataset.csv')\n",
    "print(file_toBe_cleansed.shape, \"\\n\", file_toBe_cleansed.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a77fa-b2e3-4cb3-b87b-c342c11bcb29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d10c02-0c12-4951-9fdd-568460c4a52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605547c-5856-4057-af3e-f16dd1bfdef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a552cf1-e68b-4d06-a6e0-2dbbec8d7f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b630e0-8298-4857-ba7b-b8faad4a7576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_data_type: customer_id          object\n",
      "name                 object\n",
      "email                object\n",
      "phone_number         object\n",
      "city                 object\n",
      "registration_date    object\n",
      "dtype: object \n",
      "\n",
      "column_names_list: ['customer_id', 'name', 'email', 'phone_number', 'city', 'registration_date']\n"
     ]
    }
   ],
   "source": [
    "# # DYNAMIC CAPTURE OF COLUMN NAMES IN DATAFRAME\n",
    "# # Useful when working w/ DataFrames where column names are unknown or may change\n",
    "\n",
    "# data = {'col_A': [1, 2], 'col_B': [3, 4], 'col_C': [5, 6]}\n",
    "# df = pd.DataFrame(data)\n",
    "# df\n",
    "column_data_types = file_toBe_cleansed.dtypes\n",
    "print(f\"column_data_type: {column_data_types} \\n\")\n",
    "\n",
    "\n",
    "column_names_list = file_toBe_cleansed.columns.tolist()\n",
    "print(f\"column_names_list: {column_names_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615986d-3aa3-4a9e-be73-147d5389a0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b4ff7c-961b-40eb-952e-9afc6bfc15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in file_toBe_cleansed.columns:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160b2f9-6c93-4825-8e29-02f598acd916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b03f707-ffc7-4d70-9aa8-92a121a5f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Function to clean individual DataFrame\n",
    "# def clean_dataframe(df):\n",
    "#     df = df.drop_duplicates()\n",
    "    \n",
    "#     # Fill missing values\n",
    "#     # EMAIL Addresses\n",
    "#     df['email'] = df['email'].fillna('none@none.com')\n",
    "\n",
    "#     # Phone Numbers\n",
    "#     # df['phone_number'] = df['phone_number'].fillna('N/A')\n",
    "#     df['phone_number'] = df['phone_number'].fillna('9999999999')\n",
    "\n",
    "    \n",
    "#     # Normalize text\n",
    "#     df['name'] = df['name'].str.strip().str.title()\n",
    "#     df['city'] = df['city'].str.strip().str.title()\n",
    "#     df['email'] = df['email'].str.strip()\n",
    "#     df['phone_number'] = df['phone_number'].str.strip()\n",
    "\n",
    "#     # Format dates\n",
    "#     df['registration_date'] = pd.to_datetime(df['registration_date'], errors='coerce')\n",
    "#     df['registration_date'] = df['registration_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#     # Drop rows with missing customer_id - THIS MAY BE A NON-BASIC OFFERING\n",
    "#     #df = df.dropna(subset=['customer_id'])\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1951762e-d1ba-4739-a2b5-4795232ff892",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     11\u001b[39m         df[column_name] = df[column_name].astype(\u001b[38;5;28mstr\u001b[39m).str.strip()\n\u001b[32m     13\u001b[39m         \u001b[38;5;66;03m# HANDLE BLANK/ MISSING VALUES BASED ON DATA TYPE OF COLUMN\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# STANDARDIZE NAMES\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m         \u001b[38;5;66;03m# STANDARDIZE PHONE NUMBERS\u001b[39;00m\n\u001b[32m     18\u001b[39m             \u001b[38;5;66;03m# USE REGEX EXPRESSION TO REMOVE ALL NON-NUMERIC CHARACTERS FROM FORMATTED PHONE NUMBER\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mclean_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_toBe_cleansed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mclean_dataframe\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_dataframe\u001b[39m(df):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m df.select_dtypes(include=\u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m         \u001b[38;5;66;03m# STANDARDIZE DATE / TIME FORMATS (CONVERT TO DATE/ TIME OBJECT AS NEEDED)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcolumn_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontains\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m      6\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'contains'"
     ]
    }
   ],
   "source": [
    "def clean_dataframe(df):\n",
    "    for column_name in df.select_dtypes(include=\"object\"):\n",
    "\n",
    "        # STANDARDIZE DATE / TIME FORMATS (CONVERT TO DATE/ TIME OBJECT AS NEEDED)\n",
    "        if f\"{column_name}\".contains(\"date\") in df.columns:\n",
    "            print(True)\n",
    "        else:\n",
    "            print(False)\n",
    "\n",
    "        # STRIP WHITEPSACE - ALL OBJECT/ TEXT CONTENT\n",
    "        df[column_name] = df[column_name].astype(str).str.strip()\n",
    "\n",
    "        # HANDLE BLANK/ MISSING VALUES BASED ON DATA TYPE OF COLUMN\n",
    "\n",
    "        # STANDARDIZE NAMES\n",
    "\n",
    "        # STANDARDIZE PHONE NUMBERS\n",
    "            # USE REGEX EXPRESSION TO REMOVE ALL NON-NUMERIC CHARACTERS FROM FORMATTED PHONE NUMBER\n",
    "\n",
    "\n",
    "clean_dataframe(file_toBe_cleansed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c06522a-f840-4e09-87f2-b784743b9dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e296b8b4-6220-4bcb-8f58-ccaf31286206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b27136a6-051c-460f-9c5e-2ff3d72708df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WRITE CLEANSED FILE AS OUTPUT\n",
    "# def output_file(df):\n",
    "#     # MAKE SURE TO LIST FULL PATH TO OUTPUT FILE OTHERWISE FILL WILL BE WRITTEIN IN DIRECTORY IN WHICH THIS FILE RESIDES!\n",
    "#     # df.to_csv(\"concert_tours_by_women_TEST.csv\")\n",
    "#     df.to_csv(r\"C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\data_scientist\\csv_files\\CLEANED_FILE.csv\")\n",
    "#     print(f\"Cleaned data saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143d637c-4ba8-40d9-a80b-3a965f71211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved!\n"
     ]
    }
   ],
   "source": [
    "# # FULL SAMPLE PIPELINE\n",
    "\n",
    "\n",
    "# cleaned_file = clean_dataframe(file_toBe_cleansed)\n",
    "# final_output = output_file(cleaned_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761908be-a25d-45e1-bd6e-b5fc6d634154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process each CSV in the folder\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         file_path = os.path.join(input_folder, filename)\n",
    "#         try:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             cleaned_df = clean_dataframe(df)\n",
    "            \n",
    "#             output_path = os.path.join(output_folder, f\"cleaned_{filename}\")\n",
    "#             cleaned_df.to_csv(output_path, index=False)\n",
    "            \n",
    "#             print(f\"✅ Cleaned: {filename} → {output_path}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"❌ Failed to process {filename}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
