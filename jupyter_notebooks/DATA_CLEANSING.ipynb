{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c41cd13-dda9-43b2-8823-9e4bf095edaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in c:\\users\\cessn\\miniconda3\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: IPython in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from import-ipynb) (9.2.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from import-ipynb) (5.10.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (5.14.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from nbformat->import-ipynb) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from nbformat->import-ipynb) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from nbformat->import-ipynb) (5.7.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.25.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (310)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->import-ipynb) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from stack_data->IPython->import-ipynb) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from stack_data->IPython->import-ipynb) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from stack_data->IPython->import-ipynb) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\cessn\\appdata\\roaming\\python\\python313\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\cessn\\appdata\\roaming\\python\\python313\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xlrd in c:\\users\\cessn\\miniconda3\\lib\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install import-ipynb\n",
    "%pip install openpyxl\n",
    "%pip install xlrd\n",
    "\n",
    "import import_ipynb\n",
    "import load_data\n",
    "import clean_column_names\n",
    "# import write_file_as_output\n",
    "# import normalize_strings\n",
    "# import fill_missing_values\n",
    "# import text_to_numeric\n",
    "# import drop_columns\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df735a41-f52a-4cab-bc8c-230837f54c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA NEW\n",
    "\n",
    "# Load Data\n",
    "def load_file(file_path):\n",
    "    print(file_path)\n",
    "\n",
    "    # converts filepath extension to lowercase\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    # Handle .csv files\n",
    "    \"\"\"pd.read_csv expects a file path as its argument - above line of code will not work\n",
    "    because it is being passed a DataFrame/ Series object created by load file method and saved\n",
    "    to variable named 'file'\n",
    "    \"\"\"\n",
    "    if ext in ['.csv']:\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "    # Handle excel spreadsheet files\n",
    "    elif ext in ['.xls', '.xlsx']:\n",
    "        return pd.read_excel(file_path, engine=\"openpyxl\")|pd.read_excel(file_path, engine=\"xlrd\")\n",
    "    \n",
    "    # All other files\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8560ba11-1fa5-473b-8dad-f88ef3567b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE CLEANSED FILE AS OUTPUT\n",
    "def output_file(df):\n",
    "    # MAKE SURE TO LIST FULL PATH TO OUTPUT FILE OTHERWISE FILL WILL BE WRITTEIN IN DIRECTORY IN WHICH THIS FILE RESIDES!\n",
    "    df.to_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop_CLEANSED.csv')\n",
    "    print(f\"Cleaned data saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5aaf13f-4d53-4582-9b53-0fcea55d1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop - ORIGINAL_xl.csv\n",
      "FILE READY FOR CLEANSING\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1699 entries, 0 to 1698\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   STOP ID          1674 non-null   float64\n",
      " 1   NAME             1674 non-null   object \n",
      " 2   BENCH            444 non-null    object \n",
      " 3   SHELTER          1674 non-null   object \n",
      " 4   SHELTER TYPE     176 non-null    object \n",
      " 5   RIDERSHIP ON     1586 non-null   float64\n",
      " 6   RIDERSHIP OFF    1586 non-null   float64\n",
      " 7   RIDERSHIP TOTAL  1586 non-null   float64\n",
      " 8   STOP DIRECTION   1671 non-null   object \n",
      " 9   ROUTE NO.        1674 non-null   float64\n",
      " 10  ROUTE NO. 1      285 non-null    float64\n",
      " 11  ROUTE NO. 2      54 non-null     float64\n",
      " 12  ROUTE NO. 3      16 non-null     float64\n",
      " 13  ROUTE NO. 4      12 non-null     float64\n",
      " 14  ROUTE NO. 5      11 non-null     float64\n",
      " 15  ROUTE NO. 6      9 non-null      float64\n",
      " 16  ROUTE NO. 7      3 non-null      float64\n",
      " 17  ROUTE NO. 8      1 non-null      float64\n",
      " 18  ROUTE NO. 9      1 non-null      float64\n",
      " 19  ROUTE NO. 10     1 non-null      float64\n",
      " 20  GEOMETRY         1699 non-null   object \n",
      "dtypes: float64(15), object(6)\n",
      "memory usage: 278.9+ KB\n",
      "None \n",
      "\n",
      "(1699, 21) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop - ORIGINAL_xl.csv')\n",
    "\n",
    "#Create FILE TO BE CLEANSED via deep copy of original df to new variable \n",
    "cleansed_file = df.copy()\n",
    "print(f\"FILE READY FOR CLEANSING\\n\")\n",
    "print(cleansed_file.info(),\"\\n\")\n",
    "print(cleansed_file.shape, \"\\n\")\n",
    "\n",
    "# CREATE DataFrame - ORIGINAL - DO NOT MODIFY\n",
    "    # df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop_COPY.xlsx')\n",
    "    # df = pd.read_excel(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop_COPY.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577fce5a-d342-4488-9f22-c2a8f9781630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Copy of original data file\n",
    "# file_toBe_cleansed = df.copy()\n",
    "\n",
    "# cleansed_file = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop_COPY.xlsx')\n",
    "# print(\"FILE READY FOR CLEANSING\")\n",
    "# print(\"FILE LOADED: \\n\\n \", file_toBe_cleansed, \"\\n\")\n",
    "\n",
    "#cleansed_file = clean_column_names.clean_column_names(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE: \\n\" ,cleansed_file, \"\\n\")\n",
    "\n",
    "#cleansed_file = normalize_strings.normalize_strings(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE w/ strings normalized: \\n\" ,cleansed_file ,\"\\n\")\n",
    "\n",
    "# #cleansed_file = fill_missing_values.fill_missing(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE w/ missing values filled: \\n\" ,cleansed_file ,\"\\n\")\n",
    "\n",
    "# #cleansed_file = text_to_numeric.text_to_numeric(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE w/ numbers converted to numeric values: \\n\" ,cleansed_file ,\"\\n\")\n",
    "\n",
    "# cleansed_file = drop_columns.drop_columns(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE: COLUMNS DROPPED: \\n\" ,cleansed_file ,\"\\n\")\n",
    "\n",
    "# write_file_as_output.output_file(cleansed_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224929c-484d-4de1-90ce-559427d0f966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a0e0c-2c0f-4580-8aba-b60eab3d404d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc4bd73-ecce-4f4d-b049-da28f61c8153",
   "metadata": {},
   "source": [
    "# 8 Most Common Data Cleansing Techniques:\n",
    "## 1. Dropping Columns:\n",
    "cols_to_drop = [\"column_names_to_be_dropped\"] > df_copy.drop(to_drop, axis = 1) NOTE: axis = 0 (rows) axis = 1 (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc19905-597f-4265-90f8-f9294965119b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd54ba-68ad-49ed-8b49-cbda15395af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant/ unnecessary columns\n",
    "cols_to_drop = [\"ROUTE NO. 1\",\n",
    "               'ROUTE NO. 2','ROUTE NO. 3',\n",
    "               'ROUTE NO. 4','ROUTE NO. 5','ROUTE NO. 6',\n",
    "                'ROUTE NO. 7','ROUTE NO. 8','ROUTE NO. 9','ROUTE NO. 10',\n",
    "               \"GEOMETRY\",]\n",
    "\n",
    "cleansed_file = cleansed_file.drop(cols_to_drop, axis = 1)\n",
    "output_file(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e57ce-7e6d-4c8d-99c7-3ea9b7ac9c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4984ce-b459-4dde-916b-d39989afdccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac4901-1e58-4f36-a9eb-66548bcaf17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729dd6c-2afd-4618-8e24-228f1ce9b2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab3a3858-502b-47f0-900e-686529f7eccb",
   "metadata": {},
   "source": [
    "# 2. Removing Duplicates\n",
    "## Info - https://www.w3schools.com/python/pandas/ref_df_duplicated.asp\n",
    "\n",
    "Syntax: <br>\n",
    "get duplicates returned in DataFrame Format: df_copy[df_copy.duplicated()] <br>\n",
    "get duplicates returned in Text Format: df_copy.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7404619-e7bb-4c50-a1d6-6443b2401123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum total number of duplicate rows in DataFrame BEFORE dropping dupes\n",
    "# Write this to report for client later\n",
    "cleansed_file.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0990653-8ad7-41b9-a020-f04a9389ed1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c834e5-513e-4826-8256-c694702ac681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "cleansed_file.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef6e37-8ce1-42b1-83a4-0b17102dd80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30031da4-2fc6-4e4c-8710-6273338cc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows from DataFrame + Sum total number of rows dropped\n",
    "cleansed_file = cleansed_file.drop_duplicates()\n",
    "output_file(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b21f9a-61d5-41c3-940f-3e1fd5733118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d65c5-21f9-4b25-b7d3-391d6219da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad8f1d-e180-4c8e-acec-cb4da866efd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "391f3a6c-14e5-4007-915c-9098b3878d1c",
   "metadata": {},
   "source": [
    "# 3. Removing/ Dropping Irrelevant/ Unnecessary Rows\n",
    "Syntax Ex: <br>\n",
    "Check for Jobs located in State of Ohio in DataFrame: <br>\n",
    "df_copy['Location'].str.contains(\"Oh\", case=False) <br> <br>\n",
    "df_copy['solumn_Name'].str.contains(\"specified_String\", case=False) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0aaa0-4fa2-4fc8-a66f-7aba07bdbc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd352dc5-be3e-4716-80b2-53f50520b760",
   "metadata": {},
   "source": [
    "## 4. Removing Nulls and Blanks\n",
    "# Get count of na (Not a Number values) - df_copy.isna().sum\n",
    "\n",
    "# Get count of null (null values) - df_copy.isnull().sum\n",
    "# Get count of null / na values fpr specific column - df[\"column name\"].isna() / df['column name'].isnull()\n",
    "# For multiple columns pass a list of column names in - df.[[\"list_of_column_names\"]].isna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55de5be-9e72-498b-96e3-d4a6ff839a09",
   "metadata": {},
   "source": [
    "# 4B - Filling Nulls / Blanks\n",
    "## https://www.w3schools.com/python/pandas/ref_df_fillna.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14993b-bf4a-4d4d-9e97-91c0eb863a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_file = cleansed_file.fillna(\"0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef36b8-56d9-417f-ade1-59c0acdbedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d1e56-c3c6-4bbb-9e03-f18cc891535b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d86eb-879d-4175-a090-b370acb411c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0cecb-25b2-4309-8ed9-92198a75231e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aef386-f7b6-4e97-b1d8-fe9bf1818b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05a1e790-b6e2-4c42-9678-ae9ac518c706",
   "metadata": {},
   "source": [
    "# 5 - Standardizing Values (6:26)\n",
    "\n",
    "# SYNTAX Examples: <br>\n",
    "# NOTE use df.loc as shown below to get specific column info: <br>\n",
    "df_copy.loc[row_indexer, [\"column_name\"]] <br>\n",
    "df_copy.loc[0:, [\"column_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9ae89-c501-4bee-9d54-56ef8f88fb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7340b1-1867-43fa-8048-17211fbbd969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890b3eb-e8a4-4c0d-8fd4-d39e7fb06490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE use df.loc as shown below to get specific column info\n",
    "# df_copy.loc[0:, [\"Job Title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af21e8-f098-423d-8543-b6b73852bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all elements in Job Title column where Job Title string contains a specific word\n",
    "# df_copy[df_copy[\"Job Title\"].str.contains('scientist', case=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8fd55-1b4a-4b78-87b6-c7411e312e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all strings containing word scientist to read \"Data Scientist\"\n",
    "# df_copy.loc[df_copy[\"Job Title\"].str.contains(\"scientist\", case=False), \"Job Title\"] = \"Data Scientist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b9ffb-ce7a-4422-933d-73b738f89745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to ensure fields in Job Title Column have been updated\n",
    "# df_copy.loc[:, \"Job Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4efe05-d01e-4825-b416-f63bef8a589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture /show all strings containing the letter k or K in column Salary Estimate \n",
    "# df_copy.loc[df_copy[\"Salary Estimate\"].str.contains(\"k\", case=False), \"Salary Estimate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5aa093-1376-428a-ad03-08119661f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace letter \"k\" Salary Estimate column with 000 \n",
    "# Final value: 181K - 182K > 181000 - 182000\n",
    "\n",
    "# Use dictionay object as per below syntax examples:\n",
    "\n",
    "# replace_dict ={\"\\$\": \"\", \n",
    "#                \"K\": \"000\",\n",
    "#               }\n",
    "# df_copy[\"Salary Estimate\"] = df_copy['Salary Estimate'].replace(replace_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf78f8e-c331-4f19-8c69-da24f28bee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_copy[\"Salary Estimate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3b286-e232-471e-a6b8-51cb34c11797",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37db6c23-b30b-4f5a-af84-6c8192c9ea40",
   "metadata": {},
   "source": [
    "# 6 - Splitting Columns 8:16\n",
    "## Documentation: https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html\n",
    "\n",
    "![image.png](attachment:912d4e05-947c-4236-8694-750cb88270eb.png) <br>\n",
    "![image.png](attachment:1ee4e5d9-66fa-4945-96a8-08d4825b0bfc.png) <br>\n",
    "![image.png](attachment:8d0ad171-dbdd-4a2d-a3be-5807155377ab.png) <br>\n",
    "![image.png](attachment:ecd63efd-eaf3-4dc9-8515-21feaba93a14.png) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c542a-6bcf-4956-be6b-5d464005daf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895d537-5643-47e7-afd7-7a13a28ca8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4eaf8d-4d67-4b9f-a4e6-4557f026fcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
