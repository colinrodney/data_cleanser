{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c41cd13-dda9-43b2-8823-9e4bf095edaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in c:\\users\\cessn\\miniconda3\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: IPython in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from import-ipynb) (9.2.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from import-ipynb) (5.10.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from IPython->import-ipynb) (5.14.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from nbformat->import-ipynb) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from nbformat->import-ipynb) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from nbformat->import-ipynb) (5.7.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.25.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (310)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->import-ipynb) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from stack_data->IPython->import-ipynb) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from stack_data->IPython->import-ipynb) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\cessn\\miniconda3\\lib\\site-packages (from stack_data->IPython->import-ipynb) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\cessn\\appdata\\roaming\\python\\python313\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\cessn\\appdata\\roaming\\python\\python313\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xlrd in c:\\users\\cessn\\miniconda3\\lib\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install import-ipynb\n",
    "%pip install openpyxl\n",
    "%pip install xlrd\n",
    "\n",
    "import import_ipynb\n",
    "import load_data\n",
    "import clean_column_names\n",
    "# import write_file_as_output\n",
    "# import normalize_strings\n",
    "# import fill_missing_values\n",
    "# import text_to_numeric\n",
    "# import drop_columns\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df735a41-f52a-4cab-bc8c-230837f54c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA NEW\n",
    "\n",
    "# Load Data\n",
    "def load_file(file_path):\n",
    "    print(file_path)\n",
    "\n",
    "    # converts filepath extension to lowercase\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    # Handle .csv files\n",
    "    \"\"\"pd.read_csv expects a file path as its argument - above line of code will not work\n",
    "    because it is being passed a DataFrame/ Series object created by load file method and saved\n",
    "    to variable named 'file'\n",
    "    \"\"\"\n",
    "    if ext in ['.csv']:\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "    # Handle excel spreadsheet files\n",
    "    elif ext in ['.xls', '.xlsx']:\n",
    "        return pd.read_excel(file_path, engine=\"openpyxl\")|pd.read_excel(file_path, engine=\"xlrd\")\n",
    "    \n",
    "    # All other files\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8560ba11-1fa5-473b-8dad-f88ef3567b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE CLEANSED FILE AS OUTPUT\n",
    "def output_file(df):\n",
    "    # MAKE SURE TO LIST FULL PATH TO OUTPUT FILE OTHERWISE FILL WILL BE WRITTEIN IN DIRECTORY IN WHICH THIS FILE RESIDES!\n",
    "    df.to_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop_CLEANSED.csv')\n",
    "    print(f\"Cleaned data saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5aaf13f-4d53-4582-9b53-0fcea55d1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataFrame from file at specified filepath: NOTE- This calls loaf_file() function\n",
    "def create_dataframe(file_path):\n",
    "    # df = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop - ORIGINAL_xl.csv')\n",
    "    df = load_file(file_path)\n",
    "\n",
    "    #Create FILE TO BE CLEANSED via deep copy of original df to new variable \n",
    "    deep_copied_df = df.copy()\n",
    "    print(f\"FILE READY FOR CLEANSING\\n\")\n",
    "    \n",
    "    print(deep_copied_df.info(),\"\\n\")\n",
    "    print(deep_copied_df.shape, \"\\n\")\n",
    "    return deep_copied_df\n",
    "\n",
    "# CREATE DataFrame - ORIGINAL - DO NOT MODIFY\n",
    "    # df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop_COPY.xlsx')\n",
    "    # df = pd.read_excel(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop_COPY.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9303a3d-ae70-47d2-9232-c05b1f768e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee30230b-be94-43ac-aede-cca84749b924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop - ORIGINAL_xl.csv\n",
      "FILE READY FOR CLEANSING\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1699 entries, 0 to 1698\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   STOP ID          1674 non-null   float64\n",
      " 1   NAME             1674 non-null   object \n",
      " 2   BENCH            444 non-null    object \n",
      " 3   SHELTER          1674 non-null   object \n",
      " 4   SHELTER TYPE     176 non-null    object \n",
      " 5   RIDERSHIP ON     1586 non-null   float64\n",
      " 6   RIDERSHIP OFF    1586 non-null   float64\n",
      " 7   RIDERSHIP TOTAL  1586 non-null   float64\n",
      " 8   STOP DIRECTION   1671 non-null   object \n",
      " 9   ROUTE NO.        1674 non-null   float64\n",
      " 10  ROUTE NO. 1      285 non-null    float64\n",
      " 11  ROUTE NO. 2      54 non-null     float64\n",
      " 12  ROUTE NO. 3      16 non-null     float64\n",
      " 13  ROUTE NO. 4      12 non-null     float64\n",
      " 14  ROUTE NO. 5      11 non-null     float64\n",
      " 15  ROUTE NO. 6      9 non-null      float64\n",
      " 16  ROUTE NO. 7      3 non-null      float64\n",
      " 17  ROUTE NO. 8      1 non-null      float64\n",
      " 18  ROUTE NO. 9      1 non-null      float64\n",
      " 19  ROUTE NO. 10     1 non-null      float64\n",
      " 20  GEOMETRY         1699 non-null   object \n",
      "dtypes: float64(15), object(6)\n",
      "memory usage: 278.9+ KB\n",
      "None \n",
      "\n",
      "(1699, 21) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleansed_file = create_dataframe(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop - ORIGINAL_xl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5349b1-1320-4536-a4a6-4c20b2fe58aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577fce5a-d342-4488-9f22-c2a8f9781630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Copy of original data file\n",
    "# file_toBe_cleansed = df.copy()\n",
    "\n",
    "# cleansed_file = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\city_of_baton_rouge\\cats\\Bus_Stop_COPY.xlsx')\n",
    "# print(\"FILE READY FOR CLEANSING\")\n",
    "# print(\"FILE LOADED: \\n\\n \", file_toBe_cleansed, \"\\n\")\n",
    "\n",
    "#cleansed_file = clean_column_names.clean_column_names(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE: \\n\" ,cleansed_file, \"\\n\")\n",
    "\n",
    "#cleansed_file = normalize_strings.normalize_strings(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE w/ strings normalized: \\n\" ,cleansed_file ,\"\\n\")\n",
    "\n",
    "# #cleansed_file = fill_missing_values.fill_missing(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE w/ missing values filled: \\n\" ,cleansed_file ,\"\\n\")\n",
    "\n",
    "# #cleansed_file = text_to_numeric.text_to_numeric(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE w/ numbers converted to numeric values: \\n\" ,cleansed_file ,\"\\n\")\n",
    "\n",
    "# cleansed_file = drop_columns.drop_columns(file_toBe_cleansed)\n",
    "# print(\"CLEANSED FILE: COLUMNS DROPPED: \\n\" ,cleansed_file ,\"\\n\")\n",
    "\n",
    "# write_file_as_output.output_file(cleansed_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224929c-484d-4de1-90ce-559427d0f966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a0e0c-2c0f-4580-8aba-b60eab3d404d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc4bd73-ecce-4f4d-b049-da28f61c8153",
   "metadata": {},
   "source": [
    "# 8 Most Common Data Cleansing Techniques:\n",
    "## 1. Dropping Columns:\n",
    "cols_to_drop = [\"column_names_to_be_dropped\"] > df_copy.drop(to_drop, axis = 1) NOTE: axis = 0 (rows) axis = 1 (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc19905-597f-4265-90f8-f9294965119b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81bd54ba-68ad-49ed-8b49-cbda15395af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved!\n"
     ]
    }
   ],
   "source": [
    "# Drop irrelevant/ unnecessary columns\n",
    "cols_to_drop = [\"ROUTE NO. 1\",\n",
    "               'ROUTE NO. 2','ROUTE NO. 3',\n",
    "               'ROUTE NO. 4','ROUTE NO. 5','ROUTE NO. 6',\n",
    "                'ROUTE NO. 7','ROUTE NO. 8','ROUTE NO. 9','ROUTE NO. 10',\n",
    "               \"GEOMETRY\",]\n",
    "\n",
    "cleansed_file = cleansed_file.drop(cols_to_drop, axis = 1)\n",
    "output_file(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e57ce-7e6d-4c8d-99c7-3ea9b7ac9c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4984ce-b459-4dde-916b-d39989afdccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac4901-1e58-4f36-a9eb-66548bcaf17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729dd6c-2afd-4618-8e24-228f1ce9b2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab3a3858-502b-47f0-900e-686529f7eccb",
   "metadata": {},
   "source": [
    "# 2. Removing Duplicates\n",
    "## Info - https://www.w3schools.com/python/pandas/ref_df_duplicated.asp\n",
    "\n",
    "Syntax: <br>\n",
    "get duplicates returned in DataFrame Format: df_copy[df_copy.duplicated()] <br>\n",
    "get duplicates returned in Text Format: df_copy.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7404619-e7bb-4c50-a1d6-6443b2401123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum total number of duplicate rows in DataFrame BEFORE dropping dupes\n",
    "# Write this to report for client later\n",
    "cleansed_file.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0990653-8ad7-41b9-a020-f04a9389ed1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c834e5-513e-4826-8256-c694702ac681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "cleansed_file.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef6e37-8ce1-42b1-83a4-0b17102dd80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30031da4-2fc6-4e4c-8710-6273338cc170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved!\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows from DataFrame + Sum total number of rows dropped\n",
    "cleansed_file = cleansed_file.drop_duplicates()\n",
    "output_file(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b21f9a-61d5-41c3-940f-3e1fd5733118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "147d65c5-21f9-4b25-b7d3-391d6219da9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOP ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>BENCH</th>\n",
       "      <th>SHELTER</th>\n",
       "      <th>SHELTER TYPE</th>\n",
       "      <th>RIDERSHIP ON</th>\n",
       "      <th>RIDERSHIP OFF</th>\n",
       "      <th>RIDERSHIP TOTAL</th>\n",
       "      <th>STOP DIRECTION</th>\n",
       "      <th>ROUTE NO.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1193.0</td>\n",
       "      <td>Mills @ Scenic Hwy</td>\n",
       "      <td>NB</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>S</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2824.0</td>\n",
       "      <td>Cedarcrest Ave @ Seracedar St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1191.0</td>\n",
       "      <td>Woodpecker @ Merganzer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>479.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>S</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1177.0</td>\n",
       "      <td>Blount @ Tallow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>W</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1593.0</td>\n",
       "      <td>Acadian @ Oswego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>N</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>1105.0</td>\n",
       "      <td>Scenic @ Scotlandville Library</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>REFURBISHED</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>S</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>Florida @ Eugene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>824.0</td>\n",
       "      <td>3722.0</td>\n",
       "      <td>4546.0</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1514.0</td>\n",
       "      <td>East Airport @ Goodwood</td>\n",
       "      <td>NB</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1386.0</td>\n",
       "      <td>Thomas H Delpit @ Taft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>S</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>1720.0</td>\n",
       "      <td>Airway @ Leo Skating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>S</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STOP ID                            NAME BENCH SHELTER SHELTER TYPE  \\\n",
       "0      1193.0              Mills @ Scenic Hwy    NB      NO          NaN   \n",
       "1      2824.0   Cedarcrest Ave @ Seracedar St   NaN      NO          NaN   \n",
       "2      1191.0          Woodpecker @ Merganzer   NaN      NO          NaN   \n",
       "3      1177.0                 Blount @ Tallow   NaN      NO          NaN   \n",
       "4      1593.0                Acadian @ Oswego   NaN      NO          NaN   \n",
       "...       ...                             ...   ...     ...          ...   \n",
       "1694   1105.0  Scenic @ Scotlandville Library   NaN     YES  REFURBISHED   \n",
       "1695   1996.0                Florida @ Eugene   NaN      NO          NaN   \n",
       "1696   1514.0         East Airport @ Goodwood    NB      NO          NaN   \n",
       "1697   1386.0          Thomas H Delpit @ Taft   NaN      NO          NaN   \n",
       "1698   1720.0            Airway @ Leo Skating   NaN      NO          NaN   \n",
       "\n",
       "      RIDERSHIP ON  RIDERSHIP OFF  RIDERSHIP TOTAL STOP DIRECTION  ROUTE NO.  \n",
       "0            511.0          463.0            974.0              S       11.0  \n",
       "1              NaN            NaN              NaN              S       58.0  \n",
       "2            479.0          153.0            632.0              S       11.0  \n",
       "3            319.0          460.0            779.0              W       11.0  \n",
       "4            166.0          440.0            606.0              N       20.0  \n",
       "...            ...            ...              ...            ...        ...  \n",
       "1694        1814.0          790.0           2604.0              S       10.0  \n",
       "1695         824.0         3722.0           4546.0              W       44.0  \n",
       "1696         123.0          117.0            240.0              W       18.0  \n",
       "1697         163.0           41.0            204.0              S       14.0  \n",
       "1698         257.0          189.0            446.0              S       21.0  \n",
       "\n",
       "[1675 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad8f1d-e180-4c8e-acec-cb4da866efd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "391f3a6c-14e5-4007-915c-9098b3878d1c",
   "metadata": {},
   "source": [
    "# 3. Removing/ Dropping Irrelevant/ Unnecessary Rows\n",
    "Syntax Ex: <br>\n",
    "Check for Jobs located in State of Ohio in DataFrame: <br>\n",
    "df_copy['Location'].str.contains(\"Oh\", case=False) <br> <br>\n",
    "df_copy['solumn_Name'].str.contains(\"specified_String\", case=False) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0aaa0-4fa2-4fc8-a66f-7aba07bdbc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd352dc5-be3e-4716-80b2-53f50520b760",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. Removing Nulls and Blanks\n",
    "\n",
    "## https://www.w3schools.com/python/pandas/ref_df_dropna.asp <br>\n",
    "NOTE: df_dropna() method offers more flexibility in what is dropped. <br>\n",
    "## https://www.w3schools.com/python/pandas/ref_df_drop.asp <br>\n",
    "\n",
    "\n",
    "## Get count of na (Not a Number values) - df_copy.isna().sum <br>\n",
    "\n",
    "## Get count of null (null values) - df_copy.isnull().sum<br>\n",
    "## Get count of null / na values fpr specific column - df[\"column name\"].isna() / df['column name'].isnull()<br>\n",
    "## For multiple columns pass a list of column names in - df.[[\"list_of_column_names\"]].isna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53918c25-b5bb-4249-b9fa-e4383d6fe145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Drop rows where all values are null/blank\n",
    "cleansed_file.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0abcac82-fdeb-4a3e-a553-bad74ce345ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved!\n"
     ]
    }
   ],
   "source": [
    "output_file(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53cb41-97de-4d13-b108-e9ee4df60d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc2a01-9a28-46a2-bf60-caaea0174402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7455fe8-5b25-4168-8f64-8544d512b704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50787e70-1995-4334-aa0b-40a47d9ed0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f55de5be-9e72-498b-96e3-d4a6ff839a09",
   "metadata": {},
   "source": [
    "# 4B - Filling Nulls / Blanks\n",
    "## https://www.w3schools.com/python/pandas/ref_df_fillna.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed14993b-bf4a-4d4d-9e97-91c0eb863a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cessn\\AppData\\Local\\Temp\\ipykernel_16712\\130094186.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleansed_file[column].fillna(0, inplace=True)\n",
      "C:\\Users\\Cessn\\AppData\\Local\\Temp\\ipykernel_16712\\130094186.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleansed_file[column].fillna(\"N/A\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Cast value as appropriate data type before assignment\n",
    "# cleansed_file.loc[0, ['RIDERSHIP ON', 'RIDERSHIP OFF', 'RIDERSHIP TOTAL']] = float(0)\n",
    "\n",
    "for column in cleansed_file:\n",
    "    if cleansed_file[column].dtype == 'object':\n",
    "        cleansed_file[column].fillna(\"N/A\", inplace=True)\n",
    "    cleansed_file[column].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee49e8-2cdb-44c5-b4d5-aa062d508ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd0f3f-3aef-404d-ab82-d91c85efee31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ecf9db6-39b1-43bc-964f-74ac29b7a5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved!\n"
     ]
    }
   ],
   "source": [
    "output_file(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aef386-f7b6-4e97-b1d8-fe9bf1818b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05a1e790-b6e2-4c42-9678-ae9ac518c706",
   "metadata": {},
   "source": [
    "# 5 - Standardizing Values (6:26)\n",
    "\n",
    "# SYNTAX Examples: <br>\n",
    "# NOTE use df.loc as shown below to get specific column info: <br>\n",
    "df_copy.loc[row_indexer, [\"column_name\"]] <br>\n",
    "df_copy.loc[0:, [\"column_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9ae89-c501-4bee-9d54-56ef8f88fb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7340b1-1867-43fa-8048-17211fbbd969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c890b3eb-e8a4-4c0d-8fd4-d39e7fb06490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE use df.loc as shown below to get specific column info\n",
    "# df_copy.loc[0:, [\"Job Title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30af21e8-f098-423d-8543-b6b73852bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all elements in Job Title column where Job Title string contains a specific word\n",
    "# df_copy[df_copy[\"Job Title\"].str.contains('scientist', case=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae8fd55-1b4a-4b78-87b6-c7411e312e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all strings containing word scientist to read \"Data Scientist\"\n",
    "# df_copy.loc[df_copy[\"Job Title\"].str.contains(\"scientist\", case=False), \"Job Title\"] = \"Data Scientist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "445b9ffb-ce7a-4422-933d-73b738f89745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to ensure fields in Job Title Column have been updated\n",
    "# df_copy.loc[:, \"Job Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d4efe05-d01e-4825-b416-f63bef8a589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture /show all strings containing the letter k or K in column Salary Estimate \n",
    "# df_copy.loc[df_copy[\"Salary Estimate\"].str.contains(\"k\", case=False), \"Salary Estimate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a5aa093-1376-428a-ad03-08119661f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace letter \"k\" Salary Estimate column with 000 \n",
    "# Final value: 181K - 182K > 181000 - 182000\n",
    "\n",
    "# Use dictionay object as per below syntax examples:\n",
    "\n",
    "# replace_dict ={\"\\$\": \"\", \n",
    "#                \"K\": \"000\",\n",
    "#               }\n",
    "# df_copy[\"Salary Estimate\"] = df_copy['Salary Estimate'].replace(replace_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cf78f8e-c331-4f19-8c69-da24f28bee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_copy[\"Salary Estimate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3b286-e232-471e-a6b8-51cb34c11797",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37db6c23-b30b-4f5a-af84-6c8192c9ea40",
   "metadata": {},
   "source": [
    "# 6 - Splitting Columns 8:16\n",
    "## Documentation: https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html <br>\n",
    "## Youtube: https://youtu.be/FbFQH_RNMu0?t=496\n",
    "\n",
    "## Example Code: https://docs.google.com/document/d/15Ajf-MKtOWItDITu-kukbEeshtCyMC86htXgTiMZJOA/edit?tab=t.0\n",
    "\n",
    "## SYNTAX EXAMPLES:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de839c6d-b340-4087-a26b-7b76f47cb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79fa06c6-44df-43bb-8fea-b4128395004c",
   "metadata": {},
   "source": [
    "# 7 - Convert Datatypes <br>\n",
    "## Youtube: https://youtu.be/FbFQH_RNMu0?t=613 <br>\n",
    "## Code Examples: https://docs.google.com/document/d/1HiZYEBH_5RaNjvvVtOodOFB0z-ji_4kx-kF9pv1IE-U/edit?tab=t.0 <br>\n",
    "\n",
    "## Convert datatype: multiple columns to datatype int: <br>\n",
    "convert_dtypes ={'colName_1': 'int',\n",
    "                'colName_2': 'int',} <br>\n",
    "df = df.astype(convert_dtypes) <br>\n",
    "\n",
    "# CONVERT datatype of single column <br>\n",
    "df['colName_1'] = df['colName_1'].astype(\"specify_datatype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd08a3-4021-48fd-a17c-cc64c7b108a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b1582-ac4c-4e7f-9e99-de68a240111e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b1ca15d-f013-462d-a08d-4e0e1a4199a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT RIDERSHIP columns to data type INT from datatype FLOAT:\n",
    "convert_dtypes ={'RIDERSHIP ON': 'int',\n",
    "                'RIDERSHIP OFF': 'int',\n",
    "                'RIDERSHIP TOTAL': 'int',}\n",
    "cleansed_file = cleansed_file.astype(convert_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adedd8c-5ba8-48bf-baa2-2614b0bd65f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7093e74d-51a9-416b-8424-d7b4ebf87b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved!\n"
     ]
    }
   ],
   "source": [
    "output_file(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527fd35-b0a7-4f62-9490-e87e13380ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487abd88-242a-46bc-95c4-da1112e81e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d51c852-07bc-41bd-851b-32bcf43927b2",
   "metadata": {},
   "source": [
    "# 8 - Stripping Strings <br>\n",
    "## Youtube - https://youtu.be/FbFQH_RNMu0?t=648 <br>\n",
    "\n",
    "## SYNTAX EXAMPLES\n",
    "## Cleaning special / non-word characters from end of string: <br>\n",
    "df = dfloc[:, 'column_Name'].str[:-4] - NOTE this cleans up to the last 4 characters of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213fdd43-4f08-4991-a044-cce69b6f70ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52840eb-ad72-4196-9c6a-0c714f91972e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9b4cd-9eec-41da-a6ec-166d5a66f448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0353f31-1143-44a0-a2a4-a497f1b2ce31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed427e-7f7b-46f6-8012-88dbc458bee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf563fbb-5426-4d6e-9ca7-9a632823bb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
