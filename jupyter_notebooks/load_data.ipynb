{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35032065",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Import required packages/ libraries/ frameworks from requirements.txt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# %pip install -r requirements_load_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f28ae-f951-4abd-acc3-b9845d0e1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA NEW\n",
    "\n",
    "# Load Data\n",
    "def load_file(file_path):\n",
    "\n",
    "    # converts filepath extension to lowercase\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    # Handle .csv files\n",
    "    \"\"\"pd.read_csv expects a file path as its argument - above line of code will not work\n",
    "    because it is being passed a DataFrame/ Series object created by load file method and saved\n",
    "    to variable named 'file'\n",
    "    \"\"\"\n",
    "    if ext == '.csv':\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "    # Handle excel spreadsheet files\n",
    "    elif ext in ['.xls', '.xlsx']:\n",
    "        return pd.read_excel(file_path)\n",
    "    \n",
    "    # All other files\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "\n",
    "    # CREATE DataFrame - ORIGINAL - DO NOT MODIFY\n",
    "    df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\data_scientist\\csv_files\\messy_crm_dataset.csv')\n",
    "    # print(df.info())\n",
    "\n",
    "    #Create FILE TO BE CLEANSED\n",
    "    # Call load_file function \n",
    "    file_toBe_cleansed = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\data_scientist\\csv_files\\messy_crm_dataset.csv')\n",
    "    # print(file_toBe_cleansed.shape, \"\\n\", file_toBe_cleansed.info())\n",
    "\n",
    "    return file_toBe_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed23cf7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# # Load Data - OLD\n",
    "# def load_file(file_path):\n",
    "\n",
    "#     # converts filepath extension to lowercase\n",
    "#     ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "#     # Handle .csv files\n",
    "#     \"\"\"pd.read_csv expects a file path as its argument - above line of code will not work\n",
    "#     because it is being passed a DataFrame/ Series object created by load file method and saved\n",
    "#     to variable named 'file'\n",
    "#     \"\"\"\n",
    "#     if ext == '.csv':\n",
    "#         return pd.read_csv(file_path)\n",
    "\n",
    "#     # Handle excel spreadsheet files\n",
    "#     elif ext in ['.xls', '.xlsx']:\n",
    "#         return pd.read_excel(file_path)\n",
    "    \n",
    "#     # All other files\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "#     df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\concert_tours_by_women\\concert_tours_by_women_ORIGINAL.csv')\n",
    "#     print(df.info())\n",
    "\n",
    "#     file_toBe_cleansed = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\concert_tours_by_women\\concert_tours_by_women_ORIGINAL.csv')\n",
    "#     return file_toBe_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a64d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrame from ORIGINAL file on filePath\n",
    "# df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\data_cleanser\\concert_tours_by_women_ORIGINAL.csv')\n",
    "# Create pandas DataFrame from ORIGINAL file on filePath\n",
    "# df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\concert_tours_by_women\\concert_tours_by_women_ORIGINAL.csv')\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # file = load_file(r\"example_import.csv\")\n",
    "# # THIS WORKS BUT MIGHT BE REDUNDANT\n",
    "# # file_toBe_cleansed = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\data_cleanser\\concert_tours_by_women_ORIGINAL.csv')\n",
    "# file_toBe_cleansed = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\sample_datasets\\concert_tours_by_women\\concert_tours_by_women_ORIGINAL.csv')\n",
    "# # Will this work > cleansed_file = df?\n",
    "# # print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2eea55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c92af623",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "df = pd.read_csv(file) > WILL NOT WORK - Yields TypeError: argument of type 'method' is not iterable (DO NOT DELETE!)\n",
    "df.columns reference = https://www.geeksforgeeks.org/python/python-pandas-dataframe-columns/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e64b40",
   "metadata": {},
   "source": [
    "DATA CLEANSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e58f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "# ''' Captures all column names in DataFrame + Does following actions:\n",
    "# 1. Strip whitespace (both left/right side of string)\n",
    "# 2. Convert column names to all lowercase\n",
    "# 3. Locates regex pattern specified (replaces any char that is NOT a letter or number with an underscore)\n",
    "# 4. str.strip('_') removes any underscore characters at start/ end of string \n",
    "# (https://www.w3schools.com/python/ref_string_strip.asp)\n",
    "# '''\n",
    "# def clean_column_names(df):\n",
    "#     df.columns = (\n",
    "#         df.columns.str.strip()\n",
    "#                   .str.lower()\n",
    "#                   .str.replace(r'[^a-z0-9]+', '_', regex=True)\n",
    "#                   .str.strip('_')\n",
    "#     )\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40f5f2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# CALL FUNCTION\n",
    "# cleansed_file = clean_column_names(df)\n",
    "# print(clean_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb12038",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# # Remove blank rows & duplicate rows\n",
    "# def remove_blanks_and_duplicates(df):\n",
    "\n",
    "#     # https://www.w3schools.com/python/pandas/ref_df_dropna.asp\n",
    "#     # https://www.w3schools.com/python/pandas/pandas_ref_dataframe.asp\n",
    "#     df.dropna(how='all', inplace=True) \n",
    "#     df.drop_duplicates(inplace=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4318d84",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# CALL FUNCTION\n",
    "# cleansed_file = remove_blanks_and_duplicates(df)\n",
    "# # print(\"'\\n\", cleaned_blanks_and_dupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f703e62",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# # # Strip leading/trailing whitespace and fix casing\n",
    "# def normalize_strings(df):\n",
    "\n",
    "#     '''Note: df.select_dtypes returns a subset of columns\n",
    "#     in DataFrame based on column data type (dtype)\n",
    "#     SOURCE: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html'''\n",
    "\n",
    "#     for col in df.select_dtypes(include='object'):\n",
    "#         df[col] = df[col].astype(str).str.strip()\n",
    "#         #df[col] = df[col].str.replace(r'\\W', '', regex=True) # remove all non-digit chars\n",
    "\n",
    "#         # regex pattern removes any characters that are not letters and/or numbers\n",
    "#         # works to remove replacement character (black diamond w/ white question mark in excel)\n",
    "#         df[col] = df[col].str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff061a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# CALL FUNCTION\n",
    "# cleansed_file = normalize_strings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e961c0c",
   "metadata": {},
   "source": [
    "CALL FUNCTION\n",
    "cleansed_file = remove_dollarSign(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa2b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca2cd4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# # # Handle missing values (customize as needed) - MORE TESTING REQUIRED\n",
    "# def fill_missing(df):\n",
    "#     for col in df.columns:\n",
    "#         if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "#             df[col].fillna(df[col].median(), inplace=True)\n",
    "#         else:\n",
    "#             df[col].fillna(\"MISSING\", inplace=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e22e8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# CALL FUNCTION\n",
    "# cleansed_file = fill_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8cb6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize Dates - Work ONLY w/ any year/date/month or date/ time columns in dataset\n",
    "# def normalizeDates(df):\n",
    "#      for col in df.select_dtypes(include=\"object\"): # loop\n",
    "#         #Regex pattern to be searched in string\n",
    "#         unformattedDate = \"20232024\"\n",
    "        \n",
    "#         # Compiles regular expression PATTERN to be tested/matched into regex object\n",
    "#         # this optimizes pattern for repeated use/ reusability\n",
    "#         years_Regex = re.compile(r'((\\d{4})(\\d{4}))')\n",
    "\n",
    "#         # mo = matching object\n",
    "#         mo = years_Regex.search(unformattedDate)\n",
    "\n",
    "#         #capture matching objects groups\n",
    "#         x = mo.group(1)\n",
    "#         y = mo.group(2)\n",
    "\n",
    "#         normalizedYearx = f\"{x}\"\n",
    "#         normalizedYeary = f\"{y}\"\n",
    "        \n",
    "\n",
    "#         #df[col] = df[col].str.replace(r'\\W', '', regex=True) # remove all non-digit chars\n",
    "\n",
    "#         # regex pattern removes any characters that are not letters and/or numbers\n",
    "#         # works to remove replacement character (black diamond w/ white question mark in excel)\n",
    "#         df[col] = df[col].str.replace(unformattedDate, normalizedYearx + normalizedYeary, regex=True)\n",
    "#         return df\n",
    "# cleansed_file = normalizeDates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea865b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f5adc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WRITE CLEANSED FILE AS OUTPUT\n",
    "# cleansed_file.to_csv(\"concert_tours_by_women_TEST.csv\")\n",
    "# print(f\"Cleaned data saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cde54f",
   "metadata": {},
   "source": [
    "# Run full cleaning pipeline\n",
    "def clean_data(file_path, output_path):\n",
    "    df = load_file(file_path)\n",
    "    print(f\"Loaded {len(df)} rows and {len(df.columns)} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21477674",
   "metadata": {},
   "source": [
    "    df = clean_column_names(df)\n",
    "    df = remove_blanks_and_duplicates(df)\n",
    "    df = normalize_strings(df)\n",
    "    df = fill_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f874c61",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba21906",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"example_input.csv\"\n",
    "    output_file = \"cleaned_output.csv\"\n",
    "    clean_data(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
