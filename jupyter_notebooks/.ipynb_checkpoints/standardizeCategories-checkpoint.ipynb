{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fc34b12",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Import required packages/ libraries/ frameworks from requirements.txt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ec0287",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_file(file_path):\n",
    "\n",
    "    # converts filepath extension to lowercase\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    # Handle .csv files\n",
    "    \"\"\"pd.read_csv expects a file path as its argument - above line of code will not work\n",
    "    because it is being passed a DataFrame/ Series object created by load file method and saved\n",
    "    to variable named 'file'\n",
    "    \"\"\"\n",
    "    if ext == '.csv':\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "    # Handle excel spreadsheet files\n",
    "    elif ext in ['.xls', '.xlsx']:\n",
    "        return pd.read_excel(file_path)\n",
    "    \n",
    "    # All other files\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "044a6bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21864 entries, 0 to 21863\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   USER_ID                  21864 non-null  object        \n",
      " 1   ORDER_ID                 21864 non-null  object        \n",
      " 2   PURCHASE_TS              21864 non-null  object        \n",
      " 3   SHIP_TS                  21864 non-null  datetime64[ns]\n",
      " 4   PRODUCT_NAME             21864 non-null  object        \n",
      " 5   PRODUCT_NAME_CLEANSED    21864 non-null  object        \n",
      " 6   PRODUCT_ID               21864 non-null  object        \n",
      " 7   USD_PRICE                21859 non-null  float64       \n",
      " 8   PURCHASE_PLATFORM        21864 non-null  object        \n",
      " 9   MARKETING_CHANNEL        21781 non-null  object        \n",
      " 10  ACCOUNT_CREATION_METHOD  21781 non-null  object        \n",
      " 11  COUNTRY_CODE             21826 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(10)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create pandas DataFrame from ORIGINAL file on filePath\n",
    "# df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\data_cleanser\\gamezone-orders-data\\gamezone-orders-data.csv')\n",
    "df = pd.read_excel(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\data_cleanser\\gamezone-orders-data\\gamezone-orders-data.xlsx')\n",
    "print(df.info())\n",
    "# print(\"\\n\", df.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160d337-062f-4eb5-bca7-5bb0ce6f847a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55701a2-bb9b-4cbc-908f-b42da5a25184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a0f0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = load_file(r\"example_import.csv\")\n",
    "# THIS WORKS BUT MIGHT BE REDUNDANT\n",
    "file_toBe_cleansed = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\data_cleanser\\gamezone-orders-data\\gamezone-orders-data.xlsx')\n",
    "# print(df.info())\n",
    "# Will this work > cleansed_file = df?\n",
    "# print(file)\n",
    "\n",
    "# df = pd.read_csv(file) > WILL NOT WORK - Yields TypeError: argument of type 'method' is not iterable (DO NOT DELETE!) df.columns reference = https://www.geeksforgeeks.org/python/python-pandas-dataframe-columns/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db0269-e510-4963-b25c-5fe5f92a7055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56797083-351e-48be-8978-f3e3e235e182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c88f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42a8d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANSING FUNCTIONS\n",
    "\n",
    "# Clean column names\n",
    "''' Captures all column names in DataFrame + Does following actions:\n",
    "1. Strip whitespace (both left/right side of string)\n",
    "2. Convert column names to all lowercase\n",
    "3. Locates regex pattern specified (replaces any char that is NOT a letter or number with an underscore)\n",
    "4. str.strip('_') removes any underscore characters at start/ end of string \n",
    "(https://www.w3schools.com/python/ref_string_strip.asp)\n",
    "'''\n",
    "def clean_column_names(df):\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "                  .str.lower()\n",
    "                  .str.replace(r'[^a-z0-9]+', '', regex=True)\n",
    "                  .str.strip('_')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "#CALL FUNCTION \n",
    "# cleansed_file = clean_column_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77e03c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove blank rows & duplicate rows\n",
    "def remove_blanks_and_duplicates(df):\n",
    "\n",
    "    # https://www.w3schools.com/python/pandas/ref_df_dropna.asp\n",
    "    # https://www.w3schools.com/python/pandas/pandas_ref_dataframe.asp\n",
    "    df.dropna(how='all', inplace=True) \n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n",
    "\n",
    "# CALL FUNCTION\n",
    "# cleansed_file = remove_blanks_and_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa41fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Strip leading/trailing whitespace and fix casing\n",
    "def normalize_strings(df):\n",
    "\n",
    "    '''Note: df.select_dtypes returns a subset of columns\n",
    "    in DataFrame based on column data type (dtype)\n",
    "    SOURCE: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html'''\n",
    "\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "        #df[col] = df[col].str.replace(r'\\W', '', regex=True) # remove all non-digit chars\n",
    "\n",
    "        # regex pattern removes any characters that are not letters and/or numbers\n",
    "        # works to remove replacement character (black diamond w/ white question mark in excel)\n",
    "        df[col] = df[col].str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n",
    "    return df\n",
    "# CALL FUNCTION\n",
    "cleansed_file = normalize_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb841607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2179df85",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# # Handle missing values (customize as needed) - MORE TESTING REQUIRED\n",
    "def fill_missing(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(\"MISSING\", inplace=True)\n",
    "    return df\n",
    "# CALL FUNCTION\n",
    "# cleansed_file = fill_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c91b0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Dates - Work ONLY w/ any year/date/month or date/ time columns in dataset\n",
    "def normalizeDates(df):\n",
    "    for col in df.select_dtypes(include='number'):\n",
    "        print(\"Column names: \", df.columns)\n",
    "        print(\"Data types: \", df.dtypes)\n",
    "\n",
    "        if \"years\" in df.columns:\n",
    "        # Match specific type of pattern in text columns\n",
    "     \n",
    "            \n",
    "   \n",
    "\n",
    "                    # Check if value matches regex pattern\n",
    "            # yearRegexPattern = re.compile(r'((\\d{4})(\\d{4}))')\n",
    "            # date_Pattern = re.compile(r'((\\d{4})(\\d{4}))')\n",
    "            date_pattern = re.compile(r'(\\d{4})(\\d{4})|(\\d{2}).(\\d{2}).(\\d{4})') #20002001 OR 08/14/2025\n",
    "            searchText = '20232024'\n",
    "\n",
    "            # mo = matching object\n",
    "            # mo = yearRegexPattern.search(searchText)\n",
    "    \n",
    "            #capture matching objects groups\n",
    "            match1 = date_pattern.search(searchText)\n",
    "            if match1:\n",
    "                print(\"match1 is: \", match1.group(0), match1.group(1), match1.group(2))\n",
    "            \n",
    "        # y = mo.group(2)\n",
    "        # print(\"Y is: \", type(y))\n",
    "        # z = mo.group(3)\n",
    "        # print(\"Z s: \", type(z))\n",
    "\n",
    "        # normalizedYearx = f\"{x}\"\n",
    "        # normalizedYeary = f\"{y}\"\n",
    "        # normalizedYearz= f\"{z}\"\n",
    "        \n",
    "\n",
    "            df[col] = df[col].str.replace('20232024', 'TEST', regex=True) # remove all non-digit chars\n",
    "\n",
    "    # # #     # # regex pattern removes any characters that are not letters and/or numbers\n",
    "    # # #     # # works to remove replacement character (black diamond w/ white question mark in excel)\n",
    "    # #         df[col] = df[col].str.replace(yearRegexPattern, normalizedYearx + normalizedYeary, regex=True)\n",
    "            # return df\n",
    "\n",
    "    #     #Regex pattern to be searched in string\n",
    "    # unformattedDate = (r'((\\d{4})(\\d{4}))')\n",
    "        \n",
    "    # Compiles regular expression PATTERN to be tested/matched into regex object\n",
    "    # this optimizes pattern for repeated use/ reusability\n",
    "    #     yearRegexPattern = re.compile(r'((\\d{4})(\\d{4}))')\n",
    "\n",
    "    #     # mo = matching object\n",
    "    #     mo = yearRegexPattern.search('20232024')\n",
    "\n",
    "    #     #capture matching objects groups\n",
    "    #     x = mo.group(1)\n",
    "    #     y = mo.group(2)\n",
    "\n",
    "    #     normalizedYearx = f\"{x}\"\n",
    "    #     normalizedYeary = f\"{y}\"\n",
    "        \n",
    "\n",
    "    # #     # #df[col] = df[col].str.replace(r'\\W', '', regex=True) # remove all non-digit chars\n",
    "\n",
    "    # #     # # regex pattern removes any characters that are not letters and/or numbers\n",
    "    # #     # # works to remove replacement character (black diamond w/ white question mark in excel)\n",
    "        # df['years'] = df['years'].str.replace(yearRegexPattern, normalizedYeary+ normalizedYearz, regex=True)\n",
    "\n",
    "\n",
    "        return df\n",
    "#cleansed_file = normalizeDates(df)\n",
    "# print(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bb82e-be22-4759-ae51-b56bd5b7cc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "161d1668-d755-40b8-9477-f5d67239f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        USER_ID           ORDER_ID     PURCHASE_TS    SHIP_TS  \\\n",
      "0      2c06175e   0001328c3c220830  20201224000000 2020-12-13   \n",
      "1      ee8e5bc2  0002af7a5c6100772  20201001000000 2020-09-21   \n",
      "2      9eb4efe0   0002b8350e167074  20200421000000 2020-02-16   \n",
      "3      cac7cbaf   0006d06b98385729  20200407000000 2020-04-04   \n",
      "4      6b0230bc   00097279a2f46150  20201124000000 2020-08-02   \n",
      "...         ...                ...             ...        ...   \n",
      "21859  e432cf6f   fff0b6a1e9996384  20191127000000 2019-11-29   \n",
      "21860  f4f11c04  fff4592dc6d103535  20191223000000 2019-12-26   \n",
      "21861  f4f11c04  fff4592dc6d103537  20191223000000 2019-12-26   \n",
      "21862  203ce4dd   fff829b061e16171  20210131000000 2021-02-02   \n",
      "21863  203ce4dd   fff829b061e16172  20210131000000 2021-02-02   \n",
      "\n",
      "                 PRODUCT_NAME            PRODUCT_NAME_CLEANSED PRODUCT_ID  \\\n",
      "0              NintendoSwitch  Gaming Console: Nintendo Switch       e682   \n",
      "1              NintendoSwitch  Gaming Console: Nintendo Switch       e682   \n",
      "2              NintendoSwitch  Gaming Console: Nintendo Switch       8d0d   \n",
      "3      SonyPlayStation5Bundle       Bundle: Sony Playstation 5       54ed   \n",
      "4              NintendoSwitch  Gaming Console: Nintendo Switch       8d0d   \n",
      "...                       ...                              ...        ...   \n",
      "21859  SonyPlayStation5Bundle       Bundle: Sony Playstation 5       54ed   \n",
      "21860     27in4Kgamingmonitor       Monitor: Gaming-27 in - 4K       891b   \n",
      "21861     27in4Kgamingmonitor       Monitor: Gaming-27 in - 4K       891b   \n",
      "21862         DellGamingMouse                  DellGamingMouse       8d4f   \n",
      "21863         DellGamingMouse                  DellGamingMouse       8d4f   \n",
      "\n",
      "       USD_PRICE PURCHASE_PLATFORM MARKETING_CHANNEL ACCOUNT_CREATION_METHOD  \\\n",
      "0         168.00           website         affiliate                 unknown   \n",
      "1         160.61           website            direct                 desktop   \n",
      "2         151.20           website            direct                 desktop   \n",
      "3        1132.82           website            direct                 desktop   \n",
      "4          33.89           website            direct                 desktop   \n",
      "...          ...               ...               ...                     ...   \n",
      "21859    1527.06           website            direct                 desktop   \n",
      "21860     467.88           website            direct                 desktop   \n",
      "21861     467.88           website            direct                 desktop   \n",
      "21862      67.07         mobileapp            direct                 desktop   \n",
      "21863      67.07         mobileapp            direct                 desktop   \n",
      "\n",
      "      COUNTRY_CODE  \n",
      "0               US  \n",
      "1               DE  \n",
      "2               US  \n",
      "3               AU  \n",
      "4               TR  \n",
      "...            ...  \n",
      "21859           US  \n",
      "21860           US  \n",
      "21861           US  \n",
      "21862           GB  \n",
      "21863           GB  \n",
      "\n",
      "[21864 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# STANDARDIZE CATEGORIES\n",
    "\n",
    "# Standardize Dates - Work ONLY w/ any year/date/month or date/ time columns in dataset\n",
    "def standardizeCategories(df):\n",
    "    # Dictionary of product keys and replacement values\n",
    "    products_Dict = {\n",
    "        # \"PRODUCT_NAME\":, :\"STANDARDIZED REPLACEMENT TEXT\"\n",
    "        \"28in4Kgamingmonitor\": \"Monitor: Gaming-28 in - 4K\",\n",
    "        \"28inches4Kgamingmonitor\": \"Monitor: Gaming-28 in - 4K\",\n",
    "        \"Acer Nitro V Gaming Laptop\": \"Computer: Laptop\",\n",
    "    }\n",
    "\n",
    "    for col in df.select_dtypes(include=\"object\"):\n",
    "        if \"PRODUCT_NAME\" in df.columns:\n",
    "            # df[\"PRODUCT_NAME_CLEANSED\"]= df[\"PRODUCT_NAME_CLEANSED\"].replace({\"27in4Kgamingmonitor\": \"Monitor: Gaming-28 in - 4K\",})\n",
    "            \n",
    "            # df = df.replace({\"27in4Kgamingmonitor\": \"Monitor: Gaming-28 in - 4K\",}) - THIS WORKS ON ENTIRE DATAFRAME NOT JUST SPECIFIC COLUMNS\n",
    "            df[\"PRODUCT_NAME_CLEANSED\"]= df[\"PRODUCT_NAME_CLEANSED\"].replace({\"NintendoSwitch\": \"Gaming Console: Nintendo Switch\",\n",
    "                                                                             \"SonyPlayStation5Bundle\": \"Bundle: Sony Playstation 5\",})\n",
    "\n",
    "            \"\"\" NOTES: non-dictionary like objects to replace multiple string values within a DataFrame OR Series will not work \n",
    "            in future releases of Pandas\n",
    "            \n",
    "            Suggested to pass dictionary object direct to .replace() method for multiple replacements\n",
    "            DO NOT reference a previously created dictionary as shown w/ products_Dict as this may work now , but not in future Pandas\n",
    "            updates!\"\"\"\n",
    "            \n",
    "            # return df.loc[:, \"PRODUCT_NAME\"]\n",
    "            \n",
    "        # return False\n",
    "        return df\n",
    "\n",
    "\n",
    "# Call Function\n",
    "cleansed_file = standardizeCategories(df)\n",
    "print(cleansed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c59c8c9-f0b9-4b9a-97b6-e2677f0d5858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0fa9f-ebe1-428a-847b-02ca6da87bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d09a6-1d7a-4e2b-8dff-e6e35e303a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a84044-09f0-4746-8b67-02ad7b906149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff46751-23b8-4678-8e96-c3fea84443ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dfc2a9-e5ee-474c-b668-8e5bbc6e452e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f916ae5-3397-4c1a-b8a5-4b69da050a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3defc-bb12-4d72-a594-99f9e02e5f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d441acf-22ac-49b6-98f5-81637f1942c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97906d-28b8-4341-b931-96e77c98e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889e94e-81b9-4449-9685-fdbaca9587ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8cd7c-7ae7-4d88-9c1d-19ccb735d12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"years\"] = pd.to_datetime(df[\"years\"]) #DO NOT DELETE\n",
    "        #df[\"years\"] = df[\"years\"].dt.strftime('%Y'+'-'+'%Y') #DO NOT DELETE\n",
    "        \n",
    "\n",
    "    \n",
    "# # print(df['years'].str.replace(r'((\\d{4})(\\d{4}))', \"testMe\", regex=True)) - DO NOT DELETE\n",
    "# df['years'] = df['years'].str.replace(r'((\\d{4})(\\d{4}))', \"someString\", regex=True) #- DO NOT DELETE\n",
    "# # df['years'] = df['years'].re.sub(r'((\\d{4})(\\d{4}))', r'((\\d{4}) (\\d{4}))') #- DO NOT DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5452d1c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "   \"\"\"\n",
    "   Working regex patterns:\n",
    "   (\\d{4})|(\\d{2}.\\d{2}.\\d{4}) - #20002001 OR 08/14/2025 08-14-2025 etc\n",
    "   (\\d{4})(\\d{4})|(\\d{2}).(\\d{2}).(\\d{4}) - Individual matching groups - research how match groups work\n",
    "   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b382f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE CLEANSED FILE AS OUTPUT\n",
    "cleansed_file.to_csv(\"concert_tours_by_women_TEST_NEW.csv\")\n",
    "print(f\"Cleaned data saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8cfda6",
   "metadata": {},
   "source": [
    "# Run full cleaning pipeline\n",
    "def clean_data(file_path, output_path):\n",
    "    df = load_file(file_path)\n",
    "    print(f\"Loaded {len(df)} rows and {len(df.columns)} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138baeb",
   "metadata": {},
   "source": [
    "    df = clean_column_names(df)\n",
    "    df = remove_blanks_and_duplicates(df)\n",
    "    df = normalize_strings(df)\n",
    "    df = fill_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaedb15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f885c",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"example_input.csv\"\n",
    "    output_file = \"cleaned_output.csv\"\n",
    "    clean_data(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
