{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29393be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Import required packages/ libraries/ frameworks from requirements.txt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f011b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load Data ((ORIGINAL FILE)\n",
    "def load_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[-1].lower() # converts filepath extension to lowercase\n",
    "    # Handle .csv files\n",
    "    if ext == '.csv':\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "    # Handle excel spreadsheet files\n",
    "    elif ext in ['.xls', '.xlsx']:\n",
    "        return pd.read_excel(file_path)\n",
    "    \n",
    "    # All other files\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fbf2af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# file = load_file(r\"example_import.csv\") #THIS IS THE ORIGINAL DATAFRAME!\n",
    "file = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\data_cleanser\\example_import.csv')\n",
    "# print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd7a82",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# todo - Create pandas DataFram from file on filePath\n",
    "\"\"\"\n",
    "pd.read_csv expects a file path as its argument - above line of code will not work\n",
    "because it is being passed a DataFrame/ Series object created by load file method and saved\n",
    "to variable named 'file'\n",
    "\n",
    "\"\"\"\n",
    "# df = pd.read_csv(file) > WILL NOT WORK - Yields TypeError: argument of type 'method' is not iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN ORIGIANL FILE - THIS WORKS\n",
    "df = pd.read_csv(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\data_cleanser\\example_import.csv')\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd240020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "060dc71a",
   "metadata": {},
   "source": [
    "ACTIONS BEFORE WRITING MODIFIED FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c618b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "def clean_column_names(df):\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "                  .str.lower()\n",
    "                  .str.replace(r'[^a-z0-9]+', '_', regex=True)\n",
    "                  .str.strip('_')\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172f65b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "updated_file = clean_column_names(df)\n",
    "# print(clean_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9a364",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Convert dtae/time + email to strings\n",
    "def convertToString(df):\n",
    "    df['join_date'] = df['join_date'].astype(str)\n",
    "    df[\"Email\"] = df[\"Email\"].astype(str) # convert all emaill addresses to strings\n",
    "    return df\n",
    "updated_file = convertToString(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d704fe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# STRIP LEAD / TRAILING WHITESPACE\n",
    "# Strip leading/trailing whitespace and fix casing\n",
    "def normalize_strings(df):\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "    return df\n",
    "updated_file = normalize_strings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c46afb",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21903ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE info stored in variable updated_file as output via df.to_csv() method\n",
    "df.to_csv(\"modified_csv1.csv\") # DONE/ WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in modified CSV\n",
    "modified_file = load_file(r'C:\\Users\\Cessn\\OneDrive\\Desktop\\data_cleanser\\modified_csv1.csv')\n",
    "# print(modified_file)\n",
    "\n",
    "\n",
    "\n",
    " # ACTIONS AFTER MODIFIED FILE HAS BEEN WRITTEN:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a357d",
   "metadata": {},
   "source": [
    "Remove blank rows & duplicate rows\n",
    "def remove_blanks_and_duplicates(df):\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e33e2",
   "metadata": {},
   "source": [
    "cleaned_blanks_and_dupes = remove_blanks_and_duplicates(df)\n",
    "print(\"'\\n\", cleaned_blanks_and_dupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2681dd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1361c3f",
   "metadata": {},
   "source": [
    "Normalize Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0cf6f4",
   "metadata": {},
   "source": [
    "def format_dates(df):\n",
    "    for col in df.columns:\n",
    "        # if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "        #     df[col].fillna(df[col].median(), inplace=True)\n",
    "        # else:\n",
    "        #     df[col].fillna(\"MISSING\", inplace=True)\n",
    "    # return df\n",
    "        print(col) # gets column name\n",
    "        #print(df[col]) # CLOSER\n",
    "format_dates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b824918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac244e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef80591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test this - ITERATE OVER DATAFRAME\n",
    "def testMe(df):\n",
    "    for index, row in df.iterrows():\n",
    "        # print(f\"row_index: {index}, column: {index['Name']}\")\n",
    "        # print(df.loc[index]) # prints each row of dataFrame\n",
    "        # print(row)\n",
    "        #print(df.loc[:, 'join_date'])# gets single column\n",
    "        # print(row['name']) - THIS WORKS (ABOVE LINE ALSO WORKS TO PRINT VALUES OF NAME COLUMN FROM ALL ROWS IN DF)\n",
    "        x = df['email']\n",
    "        print(x)\n",
    "testMe(modified_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e7cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50de7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
